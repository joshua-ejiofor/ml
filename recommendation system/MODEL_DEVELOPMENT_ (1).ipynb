{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7467d79",
   "metadata": {},
   "source": [
    "### Model Development and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0066847",
   "metadata": {},
   "source": [
    "##### Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7915aea2-79af-4d48-b038-a3fd598fdb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\796656\\appdata\\roaming\\python\\python311\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\program files\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\program files\\python311\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\796656\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in c:\\program files\\python311\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "065ef461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader, KNNWithMeans\n",
    "from surprise.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d065c99",
   "metadata": {},
   "source": [
    "##### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe2a4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = pd.read_csv('books_cleaned.csv')\n",
    "ratings_df = pd.read_csv('ratings_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879682d0",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "Recommendations are based on which books have the highest average rating. The recommendations are therefore independent and exclusive of titles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23634b",
   "metadata": {},
   "source": [
    "##### Content-based model\n",
    "\n",
    "Next, I will use a content-based approach to generating recommendations. In this approach, recommendations are generated based on the similarity between books. A TF-IDF matrix is created from book titles and authors, and cosine similarity is used to identify books most similar to a given book. This approach tailors recommendations by focusing on book features rather than user preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a055315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text_series):\n",
    "    try:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "    except LookupError:\n",
    "        nltk.download('stopwords')\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    cleaned_text = text_series.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "    return cleaned_text\n",
    "\n",
    "def combine_columns(df, titles, authors):\n",
    "    df['combined'] = titles + ' ' + authors\n",
    "    return df\n",
    "\n",
    "def compute_tfidf_matrix(df):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform(df['combined'])\n",
    "    return tfidf_matrix\n",
    "\n",
    "def compute_cosine_similarity(tfidf_matrix):\n",
    "    return cosine_similarity(tfidf_matrix)\n",
    "\n",
    "def find_book_index(df, titles, search_title):\n",
    "    clean_title = lambda x: re.sub(r'\\(.*?\\)', '', str(x)).lower().strip()\n",
    "    search_title = clean_title(search_title)\n",
    "    filtered_df = df[titles == search_title]\n",
    "    if not filtered_df.empty:\n",
    "        return filtered_df.index[0]\n",
    "    else:\n",
    "        print(f\"'{search_title}' not found in the dataframe.\")\n",
    "        return None\n",
    "\n",
    "def get_similar_books(df, cos_sim_matrix, idx, top_n=5, threshold=0.1):\n",
    "    similarity_scores = list(enumerate(cos_sim_matrix[idx]))\n",
    "    sorted_similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    book_indices = [i[0] for i in sorted_similarity_scores[1:] if i[1] > threshold][:top_n]\n",
    "    return df.iloc[book_indices]['book_id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c491b51c",
   "metadata": {},
   "source": [
    "#### Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b5ad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all creatures great and small (all creatures great and small, #1-2)\n",
      "the great divorce\n",
      "tender is the night\n",
      "this side of paradise\n",
      "z: a novel of zelda fitzgerald\n",
      "the beautiful and damned\n",
      "the curious case of benjamin button\n",
      "perfect you\n",
      "the short stories\n",
      "the great brain (great brain #1)\n"
     ]
    }
   ],
   "source": [
    "title = 'The Great Gatsby'\n",
    "n = 10\n",
    "books_df_titles = books_df['title']\n",
    "books_df_titles_1 = remove_stopwords(books_df_titles)\n",
    "books_df_authors = books_df['authors']\n",
    "content_books_df = combine_columns(books_df, books_df_titles_1, books_df_authors)\n",
    "\n",
    "tfidf_matrix = compute_tfidf_matrix(content_books_df)\n",
    "cos_sim_matrix = compute_cosine_similarity(tfidf_matrix)\n",
    "        \n",
    "book_idx = find_book_index(content_books_df , books_df_titles, title)\n",
    "            \n",
    "if book_idx is not None:\n",
    "    similar_books_ids = get_similar_books(content_books_df, cos_sim_matrix, book_idx, n)\n",
    "    \n",
    "    # Map the book IDs to titles in books_df\n",
    "    book_titles = books_df[books_df['book_id'].isin(similar_books_ids)]['title'].values\n",
    "    \n",
    "    # Print each title on a new line\n",
    "    for title in book_titles:\n",
    "        print(title)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c36c4",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "\n",
    "These are list of books most similar in titles and authors to the title 'The Great Gatsby'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afc79be",
   "metadata": {},
   "source": [
    "##### Content-based model with user profile\n",
    "\n",
    "Next, I will use a content-based approach with user profile to generate recommendations. In this approach, recommendations are generated by matching user preferences with book features. It builds a user profile based on the user's interactions (e.g., ratings, likes) and identifies key features the user prefers. The model then recommends books that share similar features with those preferred by the user, ensuring personalized suggestions tailored to the user’s tastes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18112372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highly_rated_titles(books_df, ratings_df, user_id, rating_threshold):\n",
    "    user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
    "    high_rated_books = user_ratings[user_ratings['rating'] >= rating_threshold]\n",
    "    high_rated_book_ids = high_rated_books['book_id'].tolist()\n",
    "\n",
    "    high_rated_titles = books_df[books_df['book_id'].isin(high_rated_book_ids)]['title'].tolist()\n",
    "    return high_rated_titles\n",
    "\n",
    "def build_user_profile(tfidf_matrix, books_df, high_rated_titles):\n",
    "    # Get the indices of high rated titles\n",
    "    relevant_indices = books_df[books_df['title'].isin(high_rated_titles)].index\n",
    "    # Select only the rows corresponding to these indices in the tfidf_matrix\n",
    "    user_profile = tfidf_matrix[relevant_indices].mean(axis=0)\n",
    "    user_profile = np.asarray(user_profile).reshape(1, -1)  # Convert to numpy array and reshape\n",
    "    return user_profile\n",
    "\n",
    "def get_similar_books_user_profile(tfidf_matrix, books_df, ratings_df, high_rated_titles, title, top_n):\n",
    "    user_profile = build_user_profile(tfidf_matrix, books_df, high_rated_titles)\n",
    "    similarity_scores = cosine_similarity(tfidf_matrix, user_profile).flatten()\n",
    "    similar_indices = similarity_scores.argsort()[::-1]\n",
    "   \n",
    "    similar_titles = books_df.iloc[similar_indices]['title'].tolist()\n",
    "   \n",
    "    similar_titles = [t for t in similar_titles if t != title][:top_n]\n",
    "   \n",
    "    return similar_titles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d188e0",
   "metadata": {},
   "source": [
    "#### Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b8960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the story of a new name (the neapolitan novels #2)\n",
      "my brilliant friend (the neapolitan novels #1)\n",
      "those who leave and those who stay (the neapolitan novels #3)\n",
      "the story of the lost child (the neapolitan novels, #4)\n",
      "the girl who played with fire (millennium, #2)\n",
      "the girl with the dragon tattoo (millennium, #1)\n",
      "the girl who kicked the hornet's nest (millennium, #3)\n",
      "people of the book\n",
      "the pearl\n",
      "year of wonders\n"
     ]
    }
   ],
   "source": [
    "title = 'The Great Gatsby'\n",
    "n = 10\n",
    "user_id = 1\n",
    "rating_threshold = 0.1\n",
    "books_df_titles = books_df['title']\n",
    "books_df_titles_1 = remove_stopwords(books_df_titles)\n",
    "books_df_authors = books_df['authors']\n",
    "content_books_df = combine_columns(books_df, books_df_titles_1, books_df_authors)\n",
    "\n",
    "tfidf_matrix = compute_tfidf_matrix(content_books_df)\n",
    "\n",
    "high_rated_titles = get_highly_rated_titles(books_df, ratings_df, user_id, rating_threshold)\n",
    "              \n",
    "similar_books = get_similar_books_user_profile(tfidf_matrix, content_books_df, ratings_df, high_rated_titles, title, n)\n",
    "    \n",
    "# Print each title on a new line\n",
    "for title in similar_books:\n",
    "    print(title)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc5ff69",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "\n",
    "These are list of books most similar in titles and authors to the title 'The Great Gatsby' inclusive of the user profile of the user with id 1.\n",
    "\n",
    "What will be the result for user with id 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f73c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the harry potter collection 1-4 (harry potter, #1-4)\n",
      "harry potter and the chamber of secrets (harry potter, #2)\n",
      "harry potter and the half-blood prince (harry potter, #6)\n",
      "harry potter and the sorcerer's stone (harry potter, #1)\n",
      "harry potter and the goblet of fire (harry potter, #4)\n",
      "harry potter and the order of the phoenix (harry potter, #5)\n",
      "harry potter and the deathly hallows (harry potter, #7)\n",
      "harry potter collection (harry potter, #1-6)\n",
      "harry potter boxed set, books 1-5 (harry potter, #1-5)\n",
      "harry potter boxset (harry potter, #1-7)\n"
     ]
    }
   ],
   "source": [
    "title = 'The Great Gatsby'\n",
    "n = 10\n",
    "user_id = 2\n",
    "rating_threshold = 0.1\n",
    "books_df_titles = books_df['title']\n",
    "books_df_titles_1 = remove_stopwords(books_df_titles)\n",
    "books_df_authors = books_df['authors']\n",
    "content_books_df = combine_columns(books_df, books_df_titles_1, books_df_authors)\n",
    "\n",
    "tfidf_matrix = compute_tfidf_matrix(content_books_df)\n",
    "\n",
    "high_rated_titles = get_highly_rated_titles(books_df, ratings_df, user_id, rating_threshold)\n",
    "              \n",
    "if book_idx is not None:\n",
    "    similar_books = get_similar_books_user_profile(tfidf_matrix, content_books_df, ratings_df, high_rated_titles, title, n)\n",
    "    \n",
    "    # Print each title on a new line\n",
    "    for title in similar_books:\n",
    "        print(title) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda82e84",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "\n",
    "These are list of books most similar in titles and authors to the title 'The Great Gatsby' inclusive of the user profile of the user with id 2.\n",
    "These are dramatically different from the titles recommended to user with id 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24feaff8",
   "metadata": {},
   "source": [
    "#### Collaborative filtering model\n",
    "Next, I will use a collaborative filtering approach to generate recommendations.\n",
    "A collaborative filtering model generates recommendations by leveraging the preferences of similar users. It identifies users with similar tastes based on their interaction history (e.g., ratings) and recommends books that those similar users have liked but the target user hasn't yet experienced. This approach captures the collective wisdom of the community to provide personalized suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d2c27fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_surprise_data(ratings_df):\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(ratings_df[[\"user_id\", \"book_id\", \"rating\"]], reader)\n",
    "    return data\n",
    "\n",
    "def build_and_train_model(trainset, k):\n",
    "    sim_options = {\n",
    "        \"name\": \"cosine\",\n",
    "        \"user_based\": False,  # Compute similarities between items\n",
    "    }\n",
    "    algo = KNNWithMeans(k=k, min_k=1, sim_options=sim_options)\n",
    "    algo.fit(trainset)\n",
    "    return algo\n",
    "\n",
    "def get_collaborative_recommendations(title, n, ratings_df, books_df, k):\n",
    "    # Create Surprise data\n",
    "    data = create_surprise_data(ratings_df)\n",
    "\n",
    "    # Build and train the model\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo = build_and_train_model(trainset, k)\n",
    "\n",
    "    # Find the book_id for the given title\n",
    "    book_id = books_df[books_df['title'].str.lower() == title.lower()]['book_id'].values[0]\n",
    "\n",
    "    # Get the inner id corresponding to the book_id\n",
    "    inner_id = algo.trainset.to_inner_iid(book_id)\n",
    "\n",
    "    # Get the neighbors of the book (n similar books)\n",
    "    neighbors = algo.get_neighbors(inner_id, k=n)\n",
    "\n",
    "    # Convert inner ids of neighbors to book_ids\n",
    "    neighbor_book_ids = [algo.trainset.to_raw_iid(inner_id) for inner_id in neighbors]\n",
    "\n",
    "    # Map book_ids back to titles\n",
    "    recommendations = books_df[books_df['book_id'].isin(neighbor_book_ids)]['title'].values\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05db238c",
   "metadata": {},
   "source": [
    "#### Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae9e02b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "في ديسمبر تنتهي كل الأحلام\n",
      "الجزار\n",
      "2 ضباط\n",
      "the magic (the secret, #3)\n",
      "diary ng panget\n",
      "fifty shades duo: fifty shades darker / fifty shades freed (fifty shades, #2-3)\n",
      "until nico (until, #4)\n",
      "صانع الظلام\n",
      "طه الغريب\n",
      "a thousand boy kisses\n"
     ]
    }
   ],
   "source": [
    "title = 'The Great Gatsby'\n",
    "n = 10\n",
    "k= 30\n",
    "\n",
    "recommendations = get_collaborative_recommendations(title, n, ratings_df, books_df, k)\n",
    "for title in recommendations:\n",
    "    print(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7017e8",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "\n",
    "These are list of books most collaboratively similar to the title 'The Great Gatsby'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dd5069",
   "metadata": {},
   "source": [
    "#### What is k and min_k?\n",
    "In the context of the `KNNWithMeans` algorithm from the Surprise library:\n",
    "\n",
    "### `k`:\n",
    "- **Description**: `k` is the number of nearest neighbors considered when predicting a user's rating for a book. It determines how many similar books (or users, if user-based) the algorithm will look at to compute the prediction.\n",
    "- **Usage**: A higher `k` means the algorithm will consider more neighbors when making predictions, potentially leading to more accurate but less personalized recommendations. A lower `k` might result in more personalized but less stable predictions.\n",
    "\n",
    "### `min_k`:\n",
    "- **Description**: `min_k` is the minimum number of neighbors required to make a prediction. If fewer than `min_k` neighbors are found, the algorithm may fall back to a baseline estimate (such as the mean rating) rather than using a potentially unreliable small number of neighbors.\n",
    "- **Usage**: `min_k` is useful for ensuring that predictions are not made based on too few neighbors, which could lead to less reliable recommendations. The default value is often `1`, meaning that at least one neighbor is needed to make a prediction.\n",
    "\n",
    "In the model, setting `k=30` and `min_k=1` means the algorithm will consider up to 30 nearest neighbors when predicting a rating, and it requires at least one neighbor to make a prediction.\n",
    "But these values were not selected arbitarily.\n",
    "They are instead results of hyper parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4b0672",
   "metadata": {},
   "source": [
    "#### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e85bcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score: 0.7982112629347284\n",
      "Best parameters: {'k': 20, 'min_k': 3, 'sim_options': {'name': 'pearson_baseline', 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# Create the Surprise data\n",
    "data = create_surprise_data(ratings_df)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'k': [10, 20, 30, 40, 50],  # Number of neighbors\n",
    "    'min_k': [1, 2, 3, 4, 5],   # Minimum number of neighbors\n",
    "    'sim_options': {\n",
    "        'name': ['cosine', 'pearson', 'pearson_baseline'],\n",
    "        'user_based': [False]  # Compute similarities between items\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=['rmse', 'mae'], cv=5, n_jobs=-1)\n",
    "exit()\n",
    "gs.fit(data)\n",
    "\n",
    "# Print the best RMSE score\n",
    "print(f\"Best RMSE score: {gs.best_score['rmse']}\")\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters: {gs.best_params['rmse']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd1b2de",
   "metadata": {},
   "source": [
    "#### Hybrid model\n",
    "I will be using a combination of content-based and collaborative model to generate recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "734d0fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "harry potter and the deathly hallows (harry potter, #7)\n",
      "harry potter boxed set, books 1-5 (harry potter, #1-5)\n",
      "harry potter and the half-blood prince (harry potter, #6)\n",
      "the magic (the secret, #3)\n",
      "diary ng panget\n",
      "the harry potter collection 1-4 (harry potter, #1-4)\n",
      "الجزار\n",
      "a thousand boy kisses\n",
      "harry potter boxset (harry potter, #1-7)\n",
      "fifty shades duo: fifty shades darker / fifty shades freed (fifty shades, #2-3)\n"
     ]
    }
   ],
   "source": [
    "title = 'The Great Gatsby'\n",
    "n = 10\n",
    "user_id = 2\n",
    "rating_threshold = 0.1\n",
    "books_df_titles = books_df['title']\n",
    "books_df_titles_1 = remove_stopwords(books_df_titles)\n",
    "books_df_authors = books_df['authors']\n",
    "content_books_df = combine_columns(books_df, books_df_titles_1, books_df_authors)\n",
    "\n",
    "tfidf_matrix = compute_tfidf_matrix(content_books_df)\n",
    "\n",
    "high_rated_titles = get_highly_rated_titles(books_df, ratings_df, user_id, rating_threshold)\n",
    "              \n",
    "content_recommendations = get_similar_books_user_profile(tfidf_matrix, content_books_df, ratings_df, high_rated_titles, title, n)\n",
    "    \n",
    "# Collaborative Filtering\n",
    "k= 30\n",
    "collaborative_recommendations = get_collaborative_recommendations(title, n, ratings_df, books_df, k)\n",
    "    \n",
    "# Hybrid approach: Combine the scores from both collaborative and content-based recommendations\n",
    "hybrid_recommendations = list(set(content_recommendations) | set(collaborative_recommendations))\n",
    "       \n",
    "# Limit to top-N hybrid recommendations\n",
    "hybrid_recommendations = hybrid_recommendations[:n]\n",
    "       \n",
    "# Print each title on a new line\n",
    "for title in hybrid_recommendations:\n",
    "    print(title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a4068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
